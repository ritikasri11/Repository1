Let's build a simple Linear Regression model.

LR: X1,X2-,X3----Y


  y = a+bx
weight of a person is linearly related to height
x=height
y = weight.

     x------>y
     height---->weight

The goal of this exercise to predict the housing prices by the given features. Let's predict the prices of the Boston Housing dataset by considering MEDV as the output variable and all the other variables as input.




1. from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression

dataset = spark.read.csv('BostonHousing.csv', header =True,inferSchema=True)



2. dataset.printSchema()

--Next step is to convert all the features from different columns into a single column and let's call this new vector column as 'Attributes' in the outputCol.
#Input all the features in one vector column

3.assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')

4. output = assembler.transform(dataset)
output.show()

#Input vs Output
5. finalized_data = output.select("Attributes","medv")

6. finalized_data.show()

--Here, 'Attributes' are in the input features from all the columns and 'medv' is the target column. Next, we should split the training and testing data according to our dataset (0.8 and 0.2 in this case).

#Split training and testing data
7. train_data,test_data = finalized_data.randomSplit([0.8,0.2])

8. regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')

#Learn to fit the model from training set
9. regressor = regressor.fit(train_data)

#To predict the prices on testing set
10. pred = regressor.evaluate(test_data)

#Predict the model
11. pred.predictions.show()